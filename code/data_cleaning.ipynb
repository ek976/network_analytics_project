{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca32042",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f9dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb45c8d",
   "metadata": {},
   "source": [
    "All the AIS files are the same time period: 01JUL2024 - 01JUL2025\n",
    "AIS data is from Global Fishing Watch and utilizes AIS data and their algorithm to identify 'apparent fishing efforts'. This is aimed to be just fishing vessel movement and activity information.\n",
    "\n",
    "Data is broken down by EEZ and High Seas Pockets (for areas outside the EEZs) and concentrated in the highy traversed parts of the WCPFC's Convention Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d223cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/AIS_data/rmi_eez.csv\n",
      "rmi_eez\n",
      "../data/AIS_data/tonga_eez.csv\n",
      "tonga_eez\n",
      "../data/AIS_data/.DS_Store\n",
      "../data/AIS_data/nauru_eez.csv\n",
      "nauru_eez\n",
      "../data/AIS_data/vanuatu_eez.csv\n",
      "vanuatu_eez\n",
      "../data/AIS_data/hsp2.csv\n",
      "hsp2\n",
      "../data/AIS_data/hsp3.csv\n",
      "hsp3\n",
      "../data/AIS_data/hsp1.csv\n",
      "hsp1\n",
      "../data/AIS_data/usa2_eez.csv\n",
      "usa2_eez\n",
      "../data/AIS_data/hsp4.csv\n",
      "hsp4\n",
      "../data/AIS_data/hsp5.csv\n",
      "hsp5\n",
      "../data/AIS_data/usa_eez.csv\n",
      "usa_eez\n",
      "../data/AIS_data/hsp7.csv\n",
      "hsp7\n",
      "../data/AIS_data/hsp6.csv\n",
      "hsp6\n",
      "../data/AIS_data/palau_eez.csv\n",
      "palau_eez\n",
      "../data/AIS_data/fsm_eez.csv\n",
      "fsm_eez\n",
      "../data/AIS_data/kirbati2_eez.csv\n",
      "kirbati2_eez\n",
      "../data/AIS_data/png_eez.csv\n",
      "png_eez\n",
      "../data/AIS_data/fiji_eez.csv\n",
      "fiji_eez\n",
      "../data/AIS_data/tuvalu_eez.csv\n",
      "tuvalu_eez\n",
      "../data/AIS_data/kiribati1_eez.csv\n",
      "kiribati1_eez\n",
      "../data/AIS_data/solomon_islands_eez.csv\n",
      "solomon_islands_eez\n",
      "Index(['flag', 'vessel_name', 'mmsi', 'imo', 'rmi_eez_fishing_hours',\n",
      "       'tonga_eez_fishing_hours', 'nauru_eez_fishing_hours',\n",
      "       'vanuatu_eez_fishing_hours', 'hsp2_fishing_hours', 'hsp3_fishing_hours',\n",
      "       'hsp1_fishing_hours', 'usa2_eez_fishing_hours', 'hsp4_fishing_hours',\n",
      "       'hsp5_fishing_hours', 'usa_eez_fishing_hours', 'hsp7_fishing_hours',\n",
      "       'hsp6_fishing_hours', 'palau_eez_fishing_hours',\n",
      "       'fsm_eez_fishing_hours', 'kirbati2_eez_fishing_hours',\n",
      "       'png_eez_fishing_hours', 'fiji_eez_fishing_hours',\n",
      "       'tuvalu_eez_fishing_hours', 'kiribati1_eez_fishing_hours',\n",
      "       'solomon_islands_eez_fishing_hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "directory_path = '../data/AIS_data'\n",
    "\n",
    "main_df = pd.DataFrame(columns=['flag', 'vessel_name', 'mmsi', 'imo'])\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    print(file_path)\n",
    "    if file_path != \"../data/AIS_data/.DS_Store\":\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        df_filter = df[['Flag', 'Vessel Name', 'MMSI', 'IMO', 'Apparent Fishing Hours']].copy()\n",
    "\n",
    "        area_name = file_path[17:][:-4]\n",
    "        print(area_name)\n",
    "\n",
    "        df_filter.columns = ['flag', 'vessel_name', 'mmsi', 'imo',str(area_name+'_fishing_hours')]\n",
    "\n",
    "        df_filter['mmsi'] = df_filter['mmsi'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "        df_filter['imo'] = df_filter['imo'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].astype(str).str.upper()\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].str.replace(\"F/V\", \"\", regex=False).str.replace(\"FV \", \"\", regex=False).str.replace(\"\\\"\", \"\", regex=False).str.replace(\".\", \"\", regex=False).str.replace('\"', '', regex=False).str.strip()\n",
    "\n",
    "        df_filter = df_filter.drop_duplicates()\n",
    "\n",
    "        main_df = pd.merge(main_df, df_filter, on = ['flag', 'vessel_name', 'mmsi', 'imo'], how = 'outer')\n",
    "\n",
    "# Replace blanks and string 'nan' with actual NaN\n",
    "main_df = main_df.replace(['', 'nan'], pd.NA)\n",
    "# resolve duplicate vessels\n",
    "# group by the first four columns and compute the mean for the rest\n",
    "grouped_df = main_df.groupby(['flag', 'vessel_name', 'mmsi', 'imo'], dropna=False).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# check columns\n",
    "print(grouped_df.columns)\n",
    "\n",
    "# write to a csv\n",
    "grouped_df.to_csv(\"../data/all_aid_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
