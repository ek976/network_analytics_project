{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca32042",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f9dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb45c8d",
   "metadata": {},
   "source": [
    "All the AIS files are the same time period: 01JUL2024 - 01JUL2025\n",
    "AIS data is from Global Fishing Watch and utilizes AIS data and their algorithm to identify 'apparent fishing efforts'. This is aimed to be just fishing vessel movement and activity information.\n",
    "\n",
    "Data is broken down by EEZ and High Seas Pockets (for areas outside the EEZs) and concentrated in the highy traversed parts of the WCPFC's Convention Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d223cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/AIS_data/rmi_eez.csv\n",
      "rmi_eez\n",
      "../data/AIS_data/tonga_eez.csv\n",
      "tonga_eez\n",
      "../data/AIS_data/.DS_Store\n",
      "../data/AIS_data/nauru_eez.csv\n",
      "nauru_eez\n",
      "../data/AIS_data/vanuatu_eez.csv\n",
      "vanuatu_eez\n",
      "../data/AIS_data/hsp2.csv\n",
      "hsp2\n",
      "../data/AIS_data/hsp3.csv\n",
      "hsp3\n",
      "../data/AIS_data/hsp1.csv\n",
      "hsp1\n",
      "../data/AIS_data/usa2_eez.csv\n",
      "usa2_eez\n",
      "../data/AIS_data/hsp4.csv\n",
      "hsp4\n",
      "../data/AIS_data/hsp5.csv\n",
      "hsp5\n",
      "../data/AIS_data/usa_eez.csv\n",
      "usa_eez\n",
      "../data/AIS_data/hsp7.csv\n",
      "hsp7\n",
      "../data/AIS_data/hsp6.csv\n",
      "hsp6\n",
      "../data/AIS_data/palau_eez.csv\n",
      "palau_eez\n",
      "../data/AIS_data/fsm_eez.csv\n",
      "fsm_eez\n",
      "../data/AIS_data/kirbati2_eez.csv\n",
      "kirbati2_eez\n",
      "../data/AIS_data/png_eez.csv\n",
      "png_eez\n",
      "../data/AIS_data/fiji_eez.csv\n",
      "fiji_eez\n",
      "../data/AIS_data/tuvalu_eez.csv\n",
      "tuvalu_eez\n",
      "../data/AIS_data/kiribati1_eez.csv\n",
      "kiribati1_eez\n",
      "../data/AIS_data/solomon_islands_eez.csv\n",
      "solomon_islands_eez\n",
      "Index(['flag', 'vessel_name', 'mmsi', 'imo', 'rmi_eez', 'tonga_eez',\n",
      "       'nauru_eez', 'vanuatu_eez', 'hsp2', 'hsp3', 'hsp1', 'usa2_eez', 'hsp4',\n",
      "       'hsp5', 'usa_eez', 'hsp7', 'hsp6', 'palau_eez', 'fsm_eez',\n",
      "       'kirbati2_eez', 'png_eez', 'fiji_eez', 'tuvalu_eez', 'kiribati1_eez',\n",
      "       'solomon_islands_eez'],\n",
      "      dtype='object')\n",
      "Index(['flag', 'vessel_name', 'mmsi', 'imo', 'fishing_hours', 'fishing_area'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_11002/1382724485.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  longer_df = pd.concat([longer_df, df_filter], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "directory_path = '../data/AIS_data'\n",
    "\n",
    "merged_df = pd.DataFrame(columns=['flag', 'vessel_name', 'mmsi', 'imo'])\n",
    "longer_df = pd.DataFrame(columns=['flag', 'vessel_name', 'mmsi', 'imo'])\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    print(file_path)\n",
    "    if file_path != \"../data/AIS_data/.DS_Store\":\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        df_filter = df[['Flag', 'Vessel Name', 'MMSI', 'IMO', 'Apparent Fishing Hours']].copy()\n",
    "\n",
    "        area_name = file_path[17:][:-4]\n",
    "        print(area_name)\n",
    "\n",
    "        df_filter.columns = ['flag', 'vessel_name', 'mmsi', 'imo',area_name]\n",
    "\n",
    "        df_filter['mmsi'] = df_filter['mmsi'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "        df_filter['imo'] = df_filter['imo'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].astype(str).str.upper()\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].str.replace(\"F/V\", \"\", regex=False).str.replace(\"FV \", \"\", regex=False).str.replace(\"\\\"\", \"\", regex=False).str.replace(\".\", \"\", regex=False).str.replace('\"', '', regex=False).str.strip()\n",
    "\n",
    "        df_filter = df_filter.drop_duplicates()\n",
    "\n",
    "        merged_df = pd.merge(merged_df, df_filter, on = ['flag', 'vessel_name', 'mmsi', 'imo'], how = 'outer')\n",
    "\n",
    "        # make a longer dataframe for network creation\n",
    "        df_filter = df[['Flag', 'Vessel Name', 'MMSI', 'IMO', 'Apparent Fishing Hours']].copy()\n",
    "        df_filter['fishing_area'] = area_name\n",
    "        df_filter.columns = ['flag', 'vessel_name', 'mmsi', 'imo','fishing_hours', 'fishing_area']\n",
    "        df_filter = df_filter.drop_duplicates()\n",
    "        df_filter = df_filter.replace(['', 'nan'], pd.NA)\n",
    "\n",
    "        longer_df = pd.concat([longer_df, df_filter], ignore_index=True)\n",
    "\n",
    "# Replace blanks and string 'nan' with actual NaN\n",
    "merged_df = merged_df.replace(['', 'nan'], pd.NA)\n",
    "# resolve duplicate vessels\n",
    "# group by the first four columns and compute the mean for the rest\n",
    "grouped_df = merged_df.groupby(['flag', 'vessel_name', 'mmsi', 'imo'], dropna=False).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# check columns\n",
    "print(grouped_df.columns)\n",
    "print(longer_df.columns)\n",
    "\n",
    "# sort dataframes\n",
    "longer_df = longer_df.sort_values(by = ['flag','vessel_name'], ascending=True).copy()\n",
    "grouped_df = grouped_df.sort_values(by = ['flag','vessel_name'], ascending=True).copy()\n",
    "\n",
    "# write to a csv\n",
    "grouped_df.to_csv(\"../data/merged_ais_data.csv\", index=False)\n",
    "longer_df.to_csv('../data/longer_ais_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
