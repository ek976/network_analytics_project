{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca32042",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "AIS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f9dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb45c8d",
   "metadata": {},
   "source": [
    "All the AIS files are the same time period: 01JUL2024 - 01JUL2025\n",
    "AIS data is from Global Fishing Watch and utilizes AIS data and their algorithm to identify 'apparent fishing efforts'. This is aimed to be just fishing vessel movement and activity information.\n",
    "\n",
    "Data is broken down by EEZ and High Seas Pockets (for areas outside the EEZs) and concentrated in the highy traversed parts of the WCPFC's Convention Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d223cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/AIS_data/rmi_eez.csv\n",
      "rmi_eez\n",
      "../data/AIS_data/tonga_eez.csv\n",
      "tonga_eez\n",
      "../data/AIS_data/.DS_Store\n",
      "../data/AIS_data/nauru_eez.csv\n",
      "nauru_eez\n",
      "../data/AIS_data/vanuatu_eez.csv\n",
      "vanuatu_eez\n",
      "../data/AIS_data/hsp2.csv\n",
      "hsp2\n",
      "../data/AIS_data/hsp3.csv\n",
      "hsp3\n",
      "../data/AIS_data/hsp1.csv\n",
      "hsp1\n",
      "../data/AIS_data/usa2_eez.csv\n",
      "usa2_eez\n",
      "../data/AIS_data/hsp4.csv\n",
      "hsp4\n",
      "../data/AIS_data/hsp5.csv\n",
      "hsp5\n",
      "../data/AIS_data/usa_eez.csv\n",
      "usa_eez\n",
      "../data/AIS_data/hsp7.csv\n",
      "hsp7\n",
      "../data/AIS_data/hsp6.csv\n",
      "hsp6\n",
      "../data/AIS_data/palau_eez.csv\n",
      "palau_eez\n",
      "../data/AIS_data/fsm_eez.csv\n",
      "fsm_eez\n",
      "../data/AIS_data/kirbati2_eez.csv\n",
      "kirbati2_eez\n",
      "../data/AIS_data/png_eez.csv\n",
      "png_eez\n",
      "../data/AIS_data/fiji_eez.csv\n",
      "fiji_eez\n",
      "../data/AIS_data/tuvalu_eez.csv\n",
      "tuvalu_eez\n",
      "../data/AIS_data/kiribati1_eez.csv\n",
      "kiribati1_eez\n",
      "../data/AIS_data/solomon_islands_eez.csv\n",
      "solomon_islands_eez\n",
      "Index(['flag', 'vessel_name', 'mmsi', 'imo', 'rmi_eez', 'tonga_eez',\n",
      "       'nauru_eez', 'vanuatu_eez', 'hsp2', 'hsp3', 'hsp1', 'usa2_eez', 'hsp4',\n",
      "       'hsp5', 'usa_eez', 'hsp7', 'hsp6', 'palau_eez', 'fsm_eez',\n",
      "       'kirbati2_eez', 'png_eez', 'fiji_eez', 'tuvalu_eez', 'kiribati1_eez',\n",
      "       'solomon_islands_eez'],\n",
      "      dtype='object')\n",
      "Index(['flag', 'vessel_name', 'mmsi', 'imo', 'fishing_hours', 'fishing_area'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_11002/1382724485.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  longer_df = pd.concat([longer_df, df_filter], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "directory_path = '../data/AIS_data'\n",
    "\n",
    "merged_df = pd.DataFrame(columns=['flag', 'vessel_name', 'mmsi', 'imo'])\n",
    "longer_df = pd.DataFrame(columns=['flag', 'vessel_name', 'mmsi', 'imo'])\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    print(file_path)\n",
    "    if file_path != \"../data/AIS_data/.DS_Store\":\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        df_filter = df[['Flag', 'Vessel Name', 'MMSI', 'IMO', 'Apparent Fishing Hours']].copy()\n",
    "\n",
    "        area_name = file_path[17:][:-4]\n",
    "        print(area_name)\n",
    "\n",
    "        df_filter.columns = ['flag', 'vessel_name', 'mmsi', 'imo',area_name]\n",
    "\n",
    "        df_filter['mmsi'] = df_filter['mmsi'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "        df_filter['imo'] = df_filter['imo'].apply(lambda x: str(int(x)) if pd.notna(x) else x)\n",
    "\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].astype(str).str.upper()\n",
    "        df_filter['vessel_name'] = df_filter['vessel_name'].str.replace(\"F/V\", \"\", regex=False).str.replace(\"FV \", \"\", regex=False).str.replace(\"\\\"\", \"\", regex=False).str.replace(\".\", \"\", regex=False).str.replace('\"', '', regex=False).str.strip()\n",
    "\n",
    "        df_filter = df_filter.drop_duplicates()\n",
    "\n",
    "        merged_df = pd.merge(merged_df, df_filter, on = ['flag', 'vessel_name', 'mmsi', 'imo'], how = 'outer')\n",
    "\n",
    "        # make a longer dataframe for network creation\n",
    "        df_filter = df[['Flag', 'Vessel Name', 'MMSI', 'IMO', 'Apparent Fishing Hours']].copy()\n",
    "        df_filter['fishing_area'] = area_name\n",
    "        df_filter.columns = ['flag', 'vessel_name', 'mmsi', 'imo','fishing_hours', 'fishing_area']\n",
    "        df_filter = df_filter.drop_duplicates()\n",
    "        df_filter = df_filter.replace(['', 'nan'], pd.NA)\n",
    "\n",
    "        longer_df = pd.concat([longer_df, df_filter], ignore_index=True)\n",
    "\n",
    "# Replace blanks and string 'nan' with actual NaN\n",
    "merged_df = merged_df.replace(['', 'nan'], pd.NA)\n",
    "# resolve duplicate vessels\n",
    "# group by the first four columns and compute the mean for the rest\n",
    "grouped_df = merged_df.groupby(['flag', 'vessel_name', 'mmsi', 'imo'], dropna=False).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# check columns\n",
    "print(grouped_df.columns)\n",
    "print(longer_df.columns)\n",
    "\n",
    "# sort dataframes\n",
    "longer_df = longer_df.sort_values(by = ['flag','vessel_name'], ascending=True).copy()\n",
    "grouped_df = grouped_df.sort_values(by = ['flag','vessel_name'], ascending=True).copy()\n",
    "\n",
    "# write to a csv\n",
    "grouped_df.to_csv(\"../data/merged_ais_data.csv\", index=False)\n",
    "longer_df.to_csv('../data/longer_ais_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f12caff",
   "metadata": {},
   "source": [
    "# Cleaning the Registered Fishing Vessel List (RFV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "210cf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert to two letter country code to three\n",
    "import pycountry\n",
    "\n",
    "# convert 2-letter country code to 3-letter code\n",
    "def alpha2_to_alpha3(code):\n",
    "    try:\n",
    "        return pycountry.countries.get(alpha_2=code).alpha_3\n",
    "    except:\n",
    "        return None \n",
    "    \n",
    "# convert country name to 3-letter code\n",
    "def name_to_alpha3(name):\n",
    "    try:\n",
    "        return pycountry.countries.get(name=name).alpha_3\n",
    "    except:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d106197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vessel type csv file\n",
    "vessel_tyes = pd.read_csv('../data/standard_code_lists/Fishery_Vessel_Types.csv')\n",
    "\n",
    "# function to convert vessel type\n",
    "def get_vessel_type_from_abbr(abbr_code):\n",
    "    match = vessel_tyes[vessel_tyes[\"Standard Abbreviation Code\"] == abbr_code]\n",
    "    if not match.empty:\n",
    "        return match.iloc[0][\"Vessel Type\"]\n",
    "    else:\n",
    "        return \"Unknown abbreviation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f36382a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vessel_name flag_2 home_port  \\\n",
      "0       OCEAN STAR     PA    PA-PTY   \n",
      "1        MONTELAPE     SV    SV-LUN   \n",
      "2       MONTELUCIA     SV    SV-LUN   \n",
      "3       MONTEROCIO     SV    SV-LUN   \n",
      "4  CHANG YI NO.368     TW    TW-KHH   \n",
      "\n",
      "                                            owner  \\\n",
      "0                          MED BFT VESSEL LIMITED   \n",
      "1  Oakcity Tuna Fishing Corporation, S.A. de C.V.   \n",
      "2    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "3    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "4                   HAI CHAN YANG FISHERY CO.,LTD   \n",
      "\n",
      "                                      ownder_address        vessel_type flag  \n",
      "0  Hangar, Triq it-Trunciera, Marsaxlokk, MXK 152...       Fish carrier  PAN  \n",
      "1  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV  \n",
      "2  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV  \n",
      "3  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV  \n",
      "4  No. 971-6, Wufang Rd., Xinyuan Township, Pingt...     Tuna longliner  TWN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_17551/3083843949.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rfv_sub['flag'] = rfv_sub['flag_2'].apply(alpha2_to_alpha3)\n",
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_17551/3083843949.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rfv_sub['vessel_type'] = rfv_sub['vessel_type'].apply(get_vessel_type_from_abbr)\n"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "rfv = pd.read_csv('../data/WCPFC_raw_RFV.csv')\n",
    "\n",
    "# get only the columns we need\n",
    "good_cols = [\"Name of fishing vessel\",\"Flag of fishing vessel\",\"Port of registry\",\"Name of the owner or owners\",\"Address of the owner or owners\",\"Type of vessel\"]\n",
    "rfv_sub = rfv[good_cols]\n",
    "# rename columns\n",
    "rfv_sub.columns = [\"vessel_name\", \"flag_2\", \"home_port\",'owner','ownder_address','vessel_type']\n",
    "\n",
    "# convert two letter code to three letter country code\n",
    "rfv_sub['flag'] = rfv_sub['flag_2'].apply(alpha2_to_alpha3)\n",
    "\n",
    "# convert fishing vessel type\n",
    "rfv_sub['vessel_type'] = rfv_sub['vessel_type'].apply(get_vessel_type_from_abbr)\n",
    "\n",
    "print(rfv_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7dc33bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vessel_name flag_2 home_port  \\\n",
      "0       OCEAN STAR     PA    PA-PTY   \n",
      "1        MONTELAPE     SV    SV-LUN   \n",
      "2       MONTELUCIA     SV    SV-LUN   \n",
      "3       MONTEROCIO     SV    SV-LUN   \n",
      "4  CHANG YI NO.368     TW    TW-KHH   \n",
      "\n",
      "                                            owner  \\\n",
      "0                          MED BFT VESSEL LIMITED   \n",
      "1  Oakcity Tuna Fishing Corporation, S.A. de C.V.   \n",
      "2    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "3    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "4                   HAI CHAN YANG FISHERY CO.,LTD   \n",
      "\n",
      "                                      ownder_address        vessel_type flag  \\\n",
      "0  Hangar, Triq it-Trunciera, Marsaxlokk, MXK 152...       Fish carrier  PAN   \n",
      "1  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "2  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "3  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "4  No. 971-6, Wufang Rd., Xinyuan Township, Pingt...     Tuna longliner  TWN   \n",
      "\n",
      "                          owner_location  \n",
      "0                        (MXK 1522, MLT)  \n",
      "1  (COLONIA SAN BENITOSAN SALVADOR, SLV)  \n",
      "2  (COLONIA SAN BENITOSAN SALVADOR, SLV)  \n",
      "3  (COLONIA SAN BENITOSAN SALVADOR, SLV)  \n",
      "4         (Pingtung County 932019, None)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_17551/3860550387.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rfv_sub['owner_location'] = rfv_sub['ownder_address'].apply(parse_state_country)\n"
     ]
    }
   ],
   "source": [
    "# parse address\n",
    "def parse_state_country(address):\n",
    "    address = str(address)\n",
    "    parts = address.split(',')\n",
    "    if len(parts) >= 2:\n",
    "        state = parts[-2].strip()\n",
    "        country = parts[-1].strip()\n",
    "        # manually fix Taiwan\n",
    "        if country == \"Taiwan (R.O.C.)\":\n",
    "            country = \"Taiwan\"\n",
    "            country_code = \"TWN\"\n",
    "        # convert to country code\n",
    "        country_code = name_to_alpha3(country)\n",
    "        return state, country_code\n",
    "    return None, None\n",
    "\n",
    "rfv_sub['owner_location'] = rfv_sub['ownder_address'].apply(parse_state_country)\n",
    "\n",
    "print(rfv_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab9796d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vessel_name flag_2 home_port  \\\n",
      "0       OCEAN STAR     PA    PA-PTY   \n",
      "1        MONTELAPE     SV    SV-LUN   \n",
      "2       MONTELUCIA     SV    SV-LUN   \n",
      "3       MONTEROCIO     SV    SV-LUN   \n",
      "4  CHANG YI NO.368     TW    TW-KHH   \n",
      "\n",
      "                                            owner  \\\n",
      "0                          MED BFT VESSEL LIMITED   \n",
      "1  Oakcity Tuna Fishing Corporation, S.A. de C.V.   \n",
      "2    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "3    OAKCITY TUNA FISHING CORPORATION S.A de C.V.   \n",
      "4                   HAI CHAN YANG FISHERY CO.,LTD   \n",
      "\n",
      "                                      ownder_address        vessel_type flag  \\\n",
      "0  Hangar, Triq it-Trunciera, Marsaxlokk, MXK 152...       Fish carrier  PAN   \n",
      "1  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "2  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "3  CALLE LOMA LINDA, NO.251, COLONIA SAN BENITOSA...  Tuna purse seiner  SLV   \n",
      "4  No. 971-6, Wufang Rd., Xinyuan Township, Pingt...     Tuna longliner  TWN   \n",
      "\n",
      "                          owner_location                       h_port  \n",
      "0                        (MXK 1522, MLT)             (Panama, Panama)  \n",
      "1  (COLONIA SAN BENITOSAN SALVADOR, SLV)      (La Union, El Salvador)  \n",
      "2  (COLONIA SAN BENITOSAN SALVADOR, SLV)      (La Union, El Salvador)  \n",
      "3  (COLONIA SAN BENITOSAN SALVADOR, SLV)      (La Union, El Salvador)  \n",
      "4         (Pingtung County 932019, None)  (Kaohsiung, Chinese Taipei)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9r/1lhfzshj5bvf1d4ybbng0kr00000gn/T/ipykernel_17551/184873764.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rfv_sub['h_port'] = rfv_sub['home_port'].apply(get_port_code)\n"
     ]
    }
   ],
   "source": [
    "# covert home port list\n",
    "port_codes = pd.read_csv('../data/standard_code_lists/port_code_list.csv')\n",
    "\n",
    "# function to convert vessel type\n",
    "def get_port_code(abbr_code):\n",
    "    match = port_codes[port_codes[\"Port Code\"] == abbr_code]\n",
    "    if not match.empty:\n",
    "        port = match.iloc[0][\"Port Name\"]\n",
    "        country = match.iloc[0][\"Location Country\"]            \n",
    "        return port, country\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "rfv_sub['h_port'] = rfv_sub['home_port'].apply(get_port_code)\n",
    "\n",
    "print(rfv_sub.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
